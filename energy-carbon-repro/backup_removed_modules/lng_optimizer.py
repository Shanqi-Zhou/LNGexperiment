#!/usr/bin/env python3
"""
LNGé¡¹ç›®ä¼˜åŒ–å…¥å£è„šæœ¬ - ä¼ä¸šçº§ç”Ÿäº§å°±ç»ªç‰ˆæœ¬
==========================================

é›†æˆæ‰€æœ‰ä¼˜åŒ–æ¨¡å—çš„ç»Ÿä¸€å…¥å£ç‚¹ï¼š
- Day 1-3: åŸºç¡€æ€§èƒ½ä¼˜åŒ–ï¼ˆæ•°å€¼ç¨³å®šæ€§ã€å‘é‡åŒ–ã€å¹¶è¡Œå¤„ç†ï¼‰
- Week 2: ä¼ä¸šçº§è´¨é‡æå‡ï¼ˆå¼‚å¸¸æ£€æµ‹ã€ç”Ÿäº§GPRã€éªŒè¯æ¡†æ¶ï¼‰
- ç»Ÿä¸€é…ç½®ç®¡ç†ã€æ—¥å¿—è®°å½•ã€ç›‘æ§å’ŒæŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
    python lng_optimizer.py --mode optimization --data path/to/data.csv
    python lng_optimizer.py --mode benchmark --compare all
    python lng_optimizer.py --mode validation --model path/to/model.pkl
    python lng_optimizer.py --mode pipeline --config config.yaml
"""

import os
import sys
import argparse
import yaml
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime
import warnings

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'src'))

import numpy as np
import pandas as pd

# å¯¼å…¥ä¼˜åŒ–æ¨¡å—
try:
    from src.week2_optimization_integration import Week2OptimizationPipeline, run_week2_optimization
    from src.features.enhanced_feature_extraction import EnhancedFeatureExtractor
    from src.preprocessing.robust_outlier_detection import OptimizedHampelFilter, AdaptiveHampelFilter
    from src.models.production_gpr import ProductionGPR
    from src.features.production_cache import CacheManager
    from src.benchmarking.performance_benchmark import PerformanceBenchmark
    from src.validation.automated_validation import AutomatedValidation, validate_model
    from src.monitoring.resource_monitor import ResourceMonitor
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰ä¼˜åŒ–æ¨¡å—å·²æ­£ç¡®å®‰è£…")
    sys.exit(1)


class LNGOptimizerCLI:
    """LNGä¼˜åŒ–å™¨å‘½ä»¤è¡Œæ¥å£"""

    def __init__(self):
        self.version = "1.0.0-production"
        self.author = "LNG Optimization Team"
        self.setup_logging()

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)

        # é…ç½®æ—¥å¿—æ ¼å¼
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"lng_optimizer_{timestamp}.log"

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )

        self.logger = logging.getLogger('LNGOptimizer')
        self.logger.info(f"LNGä¼˜åŒ–å™¨å¯åŠ¨ - ç‰ˆæœ¬ {self.version}")

    def create_parser(self) -> argparse.ArgumentParser:
        """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
        parser = argparse.ArgumentParser(
            description="LNGé¡¹ç›®ä¼˜åŒ–å…¥å£è„šæœ¬ - ä¼ä¸šçº§ç”Ÿäº§ç‰ˆæœ¬",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  åŸºç¡€ä¼˜åŒ–æ¨¡å¼:
    python lng_optimizer.py --mode optimization --data data/sim_lng/full_simulation_data.csv

  åŸºå‡†æµ‹è¯•æ¨¡å¼:
    python lng_optimizer.py --mode benchmark --data data.csv --compare baseline,optimized

  æ¨¡å‹éªŒè¯æ¨¡å¼:
    python lng_optimizer.py --mode validation --data data.csv --target-column energy

  å®Œæ•´æµæ°´çº¿æ¨¡å¼:
    python lng_optimizer.py --mode pipeline --config configs/production.yaml

  æ€§èƒ½åˆ†ææ¨¡å¼:
    python lng_optimizer.py --mode analysis --data data.csv --output reports/
            """)

        # ä¸»è¦å‚æ•°
        parser.add_argument('--mode',
                          choices=['optimization', 'benchmark', 'validation', 'pipeline', 'analysis', 'info'],
                          default='optimization',
                          help='è¿è¡Œæ¨¡å¼ (é»˜è®¤: optimization)')

        parser.add_argument('--data', type=str,
                          help='è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ (CSVæ ¼å¼)')

        parser.add_argument('--config', type=str,
                          default='configs/default.yaml',
                          help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: configs/default.yaml)')

        parser.add_argument('--output', type=str,
                          default='results',
                          help='è¾“å‡ºç›®å½• (é»˜è®¤: results)')

        # ä¼˜åŒ–ç›¸å…³å‚æ•°
        parser.add_argument('--target-column', type=str,
                          default='energy',
                          help='ç›®æ ‡åˆ—å (é»˜è®¤: energy)')

        parser.add_argument('--optimization-level',
                          choices=['basic', 'standard', 'advanced', 'enterprise'],
                          default='enterprise',
                          help='ä¼˜åŒ–çº§åˆ« (é»˜è®¤: enterprise)')

        # åŸºå‡†æµ‹è¯•å‚æ•°
        parser.add_argument('--compare', type=str,
                          default='all',
                          help='åŸºå‡†å¯¹æ¯”æ¨¡å¼: baseline,optimized,all (é»˜è®¤: all)')

        parser.add_argument('--test-sizes', type=str,
                          default='1000,5000,10000',
                          help='æµ‹è¯•æ•°æ®å¤§å°åˆ—è¡¨ (é»˜è®¤: 1000,5000,10000)')

        # éªŒè¯å‚æ•°
        parser.add_argument('--validation-split', type=float,
                          default=0.2,
                          help='éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤: 0.2)')

        parser.add_argument('--validation-metrics', type=str,
                          default='r2,cv_rmse,nmbe',
                          help='éªŒè¯æŒ‡æ ‡åˆ—è¡¨ (é»˜è®¤: r2,cv_rmse,nmbe)')

        # ç¼“å­˜å’Œèµ„æºç®¡ç†
        parser.add_argument('--enable-cache', action='store_true',
                          default=True,
                          help='å¯ç”¨ç‰¹å¾ç¼“å­˜ (é»˜è®¤: True)')

        parser.add_argument('--cache-dir', type=str,
                          default='cache',
                          help='ç¼“å­˜ç›®å½• (é»˜è®¤: cache)')

        parser.add_argument('--max-workers', type=int,
                          default=None,
                          help='æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: è‡ªåŠ¨æ£€æµ‹)')

        # å…¶ä»–å‚æ•°
        parser.add_argument('--verbose', '-v', action='store_true',
                          help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')

        parser.add_argument('--quiet', '-q', action='store_true',
                          help='é™é»˜æ¨¡å¼')

        parser.add_argument('--version', action='version',
                          version=f'LNG Optimizer {self.version}')

        return parser

    def load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_path = Path(config_path)

        if not config_path.exists():
            self.logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self.get_default_config()

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                if config_path.suffix.lower() == '.yaml' or config_path.suffix.lower() == '.yml':
                    config = yaml.safe_load(f)
                else:
                    config = json.load(f)

            self.logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
            return config

        except Exception as e:
            self.logger.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            self.logger.info("ä½¿ç”¨é»˜è®¤é…ç½®")
            return self.get_default_config()

    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'optimization': {
                'hampel_window': 15,
                'hampel_sigma': 3.0,
                'use_adaptive_hampel': True,
                'gpr_auto_tune': True,
                'gpr_validation_split': 0.2,
                'feature_window_size': 180,
                'feature_stride': 30,
                'enable_caching': True,
                'cache_max_size_gb': 2.0,
                'enable_parallel': True,
                'max_workers': None
            },
            'validation': {
                'target_metrics': {
                    'r2_min': 0.75,
                    'cv_rmse_max': 0.06,
                    'nmbe_max': 0.006,
                    'mae_max_percent': 5.0,
                    'inference_time_per_sample_ms': 10.0
                }
            },
            'benchmark': {
                'test_data_sizes': [1000, 5000, 10000],
                'n_runs': 3,
                'enable_visualization': True
            },
            'logging': {
                'level': 'INFO',
                'save_logs': True,
                'log_dir': 'logs'
            }
        }

    def mode_optimization(self, args) -> bool:
        """ä¼˜åŒ–æ¨¡å¼ - è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–æµæ°´çº¿"""
        self.logger.info("=== å¼€å§‹ä¼˜åŒ–æ¨¡å¼ ===")

        if not args.data:
            self.logger.error("ä¼˜åŒ–æ¨¡å¼éœ€è¦æŒ‡å®šæ•°æ®æ–‡ä»¶")
            return False

        try:
            # åŠ è½½æ•°æ®
            self.logger.info(f"åŠ è½½æ•°æ®: {args.data}")
            data = pd.read_csv(args.data)
            self.logger.info(f"æ•°æ®å½¢çŠ¶: {data.shape}")

            # é…ç½®ä¼˜åŒ–å‚æ•°
            config = self.load_config(args.config)
            optimization_config = config.get('optimization', {})

            # æ›´æ–°é…ç½®
            if args.enable_cache:
                optimization_config['enable_caching'] = True
                optimization_config['cache_dir'] = args.cache_dir

            if args.max_workers:
                optimization_config['max_workers'] = args.max_workers

            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = Path(args.output)
            output_dir.mkdir(exist_ok=True, parents=True)
            optimization_config['output_dir'] = str(output_dir)

            # è¿è¡ŒWeek 2å®Œæ•´ä¼˜åŒ–
            self.logger.info("å¯åŠ¨Week 2å®Œæ•´ä¼˜åŒ–æµæ°´çº¿")
            results = run_week2_optimization(
                data=data,
                target_column=args.target_column,
                config=optimization_config,
                pipeline_name=f"cli_optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )

            # ä¿å­˜ç»“æœæ‘˜è¦
            summary_file = output_dir / "optimization_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, default=str)

            self.logger.info(f"ä¼˜åŒ–å®Œæˆ! ç»“æœä¿å­˜è‡³: {summary_file}")

            # æ‰“å°å…³é”®æŒ‡æ ‡
            if results.get('status') == 'completed':
                total_time = results.get('total_processing_time', 0)
                stages_completed = len([s for s in results.get('stages', {}).values()
                                     if s.get('status') == 'completed'])

                print(f"\nğŸ‰ ä¼˜åŒ–æˆåŠŸå®Œæˆ!")
                print(f"ğŸ“Š å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
                print(f"âœ… å®Œæˆé˜¶æ®µ: {stages_completed}ä¸ª")
                print(f"ğŸ“ ç»“æœç›®å½•: {output_dir}")

            return True

        except Exception as e:
            self.logger.error(f"ä¼˜åŒ–è¿‡ç¨‹å¤±è´¥: {e}")
            return False

    def mode_benchmark(self, args) -> bool:
        """åŸºå‡†æµ‹è¯•æ¨¡å¼"""
        self.logger.info("=== å¼€å§‹åŸºå‡†æµ‹è¯•æ¨¡å¼ ===")

        if not args.data:
            self.logger.error("åŸºå‡†æµ‹è¯•æ¨¡å¼éœ€è¦æŒ‡å®šæ•°æ®æ–‡ä»¶")
            return False

        try:
            # è§£ææµ‹è¯•å¤§å°
            test_sizes = [int(x.strip()) for x in args.test_sizes.split(',')]

            # åˆ›å»ºåŸºå‡†æµ‹è¯•å™¨
            output_dir = Path(args.output) / 'benchmarks'
            benchmark = PerformanceBenchmark(
                test_data_sizes=test_sizes,
                output_dir=str(output_dir)
            )

            # å®šä¹‰åŸºçº¿å’Œä¼˜åŒ–æ–¹æ³•
            def baseline_extractor(data):
                """åŸºçº¿æ–¹æ³•"""
                extractor = EnhancedFeatureExtractor()
                return extractor.extract_features_single_threaded(data)

            def optimized_extractor(data):
                """ä¼˜åŒ–æ–¹æ³•"""
                extractor = EnhancedFeatureExtractor()
                return extractor.extract_features_optimized(data)

            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            self.logger.info("å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•")
            results = benchmark.run_complete_benchmark(
                baseline_extractor=baseline_extractor,
                optimized_extractor=optimized_extractor
            )

            self.logger.info(f"åŸºå‡†æµ‹è¯•å®Œæˆ! ç»“æœä¿å­˜è‡³: {output_dir}")
            return True

        except Exception as e:
            self.logger.error(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            return False

    def mode_validation(self, args) -> bool:
        """éªŒè¯æ¨¡å¼"""
        self.logger.info("=== å¼€å§‹éªŒè¯æ¨¡å¼ ===")

        if not args.data:
            self.logger.error("éªŒè¯æ¨¡å¼éœ€è¦æŒ‡å®šæ•°æ®æ–‡ä»¶")
            return False

        try:
            # åŠ è½½æ•°æ®
            data = pd.read_csv(args.data)

            # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
            if args.target_column not in data.columns:
                self.logger.error(f"ç›®æ ‡åˆ—'{args.target_column}'ä¸åœ¨æ•°æ®ä¸­")
                return False

            # ç‰¹å¾æå–
            self.logger.info("æ‰§è¡Œç‰¹å¾æå–")
            extractor = EnhancedFeatureExtractor()
            features = extractor.extract_features_optimized(
                data.drop(columns=[args.target_column]).values
            )
            target = data[args.target_column].values

            # åˆ†å‰²æ•°æ®
            split_idx = int(len(features) * (1 - args.validation_split))
            X_train = features[:split_idx]
            X_test = features[split_idx:]
            y_train = target[:split_idx]
            y_test = target[split_idx:]

            # è®­ç»ƒæ¨¡å‹
            self.logger.info("è®­ç»ƒç”Ÿäº§çº§GPRæ¨¡å‹")
            model = ProductionGPR(n_samples=len(X_train))
            model.fit_with_validation(X_train, y_train)

            # è¿è¡ŒéªŒè¯
            self.logger.info("å¼€å§‹è‡ªåŠ¨åŒ–éªŒè¯")
            config = self.load_config(args.config)
            validator = AutomatedValidation(
                target_metrics=config.get('validation', {}).get('target_metrics'),
                output_dir=str(Path(args.output) / 'validation')
            )

            validation_results = validator.run_full_validation(
                model, X_test, y_test, X_train, y_train,
                f"cli_validation_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )

            # æ‰“å°éªŒè¯æ‘˜è¦
            overall = validation_results['overall_assessment']
            print(f"\nğŸ“Š éªŒè¯ç»“æœæ‘˜è¦:")
            print(f"æ€»ä½“è¯„åˆ†: {overall['overall_score']:.1f}/100")
            print(f"éªŒè¯çŠ¶æ€: {'âœ… é€šè¿‡' if overall['validation_passed'] else 'âŒ æœªé€šè¿‡'}")
            print(f"éƒ¨ç½²å°±ç»ª: {'âœ… æ˜¯' if overall['deployment_ready'] else 'âŒ å¦'}")

            return True

        except Exception as e:
            self.logger.error(f"éªŒè¯è¿‡ç¨‹å¤±è´¥: {e}")
            return False

    def mode_pipeline(self, args) -> bool:
        """å®Œæ•´æµæ°´çº¿æ¨¡å¼"""
        self.logger.info("=== å¼€å§‹å®Œæ•´æµæ°´çº¿æ¨¡å¼ ===")

        try:
            config = self.load_config(args.config)

            # åˆ›å»ºWeek 2ä¼˜åŒ–æµæ°´çº¿
            pipeline = Week2OptimizationPipeline(config=config.get('optimization'))

            # å¦‚æœæŒ‡å®šäº†æ•°æ®æ–‡ä»¶ï¼Œè¿è¡Œå®Œæ•´å¤„ç†
            if args.data:
                data = pd.read_csv(args.data)
                results = pipeline.process_complete_pipeline(
                    data=data,
                    target_column=args.target_column,
                    pipeline_name=f"cli_pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                )

                # æ‰“å°æµæ°´çº¿æ‘˜è¦
                if results.get('status') == 'completed':
                    print(f"\nğŸ‰ æµæ°´çº¿æ‰§è¡ŒæˆåŠŸ!")
                    print(f"ğŸ“Š æ€»å¤„ç†æ—¶é—´: {results.get('total_processing_time', 0):.2f}ç§’")

                    # æ‰“å°å„é˜¶æ®µæ—¶é—´
                    print(f"\nğŸ“‹ é˜¶æ®µæ‰§è¡Œæ—¶é—´:")
                    for stage_name, stage_data in results.get('stages', {}).items():
                        if isinstance(stage_data, dict) and 'processing_time' in stage_data:
                            status_icon = "âœ…" if stage_data.get('status') == 'completed' else "âŒ"
                            print(f"  {stage_name}: {stage_data['processing_time']:.2f}ç§’ {status_icon}")

            # æ‰“å°ä¼˜åŒ–æ‘˜è¦
            summary = pipeline.get_optimization_summary()
            print(f"\nğŸ“ˆ ä¼˜åŒ–æ‘˜è¦:")
            print(f"æ‰§è¡Œæµæ°´çº¿æ•°: {summary['total_pipelines_executed']}")

            return True

        except Exception as e:
            self.logger.error(f"æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            return False

    def mode_analysis(self, args) -> bool:
        """æ€§èƒ½åˆ†ææ¨¡å¼"""
        self.logger.info("=== å¼€å§‹æ€§èƒ½åˆ†ææ¨¡å¼ ===")

        if not args.data:
            self.logger.error("åˆ†ææ¨¡å¼éœ€è¦æŒ‡å®šæ•°æ®æ–‡ä»¶")
            return False

        try:
            # åŠ è½½æ•°æ®
            data = pd.read_csv(args.data)

            # åˆ›å»ºåˆ†ææŠ¥å‘Šç›®å½•
            analysis_dir = Path(args.output) / 'analysis'
            analysis_dir.mkdir(exist_ok=True, parents=True)

            # å¯åŠ¨èµ„æºç›‘æ§
            monitor = ResourceMonitor()
            monitor.start_monitoring()

            # æ‰§è¡Œå„ç§åˆ†æ
            analysis_results = {}

            # 1. æ•°æ®è´¨é‡åˆ†æ
            self.logger.info("æ‰§è¡Œæ•°æ®è´¨é‡åˆ†æ")
            hampel_filter = AdaptiveHampelFilter()
            filtered_data = hampel_filter.filter_adaptive(data.select_dtypes(include=[np.number]))
            outlier_stats = hampel_filter.get_outlier_statistics()
            analysis_results['data_quality'] = outlier_stats

            # 2. ç‰¹å¾æå–æ€§èƒ½åˆ†æ
            self.logger.info("æ‰§è¡Œç‰¹å¾æå–æ€§èƒ½åˆ†æ")
            extractor = EnhancedFeatureExtractor()

            start_time = pd.Timestamp.now()
            features = extractor.extract_features_optimized(data.select_dtypes(include=[np.number]).values)
            end_time = pd.Timestamp.now()

            analysis_results['feature_extraction'] = {
                'processing_time_seconds': (end_time - start_time).total_seconds(),
                'input_shape': data.shape,
                'output_shape': features.shape,
                'features_per_second': features.shape[0] / (end_time - start_time).total_seconds()
            }

            # 3. ç³»ç»Ÿèµ„æºåˆ†æ
            monitor.stop_monitoring()
            resource_summary = monitor.get_summary()
            analysis_results['resource_usage'] = resource_summary

            # ä¿å­˜åˆ†æç»“æœ
            analysis_file = analysis_dir / f"performance_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_results, f, indent=2, default=str)

            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            self.generate_analysis_report(analysis_results, analysis_dir)

            self.logger.info(f"æ€§èƒ½åˆ†æå®Œæˆ! ç»“æœä¿å­˜è‡³: {analysis_dir}")
            return True

        except Exception as e:
            self.logger.error(f"æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            return False

    def mode_info(self, args) -> bool:
        """ä¿¡æ¯æ¨¡å¼ - æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€å’Œé…ç½®"""
        print(f"""
ğŸš€ LNGé¡¹ç›®ä¼˜åŒ–å™¨ - ä¼ä¸šçº§ç”Ÿäº§ç‰ˆæœ¬
======================================

ç‰ˆæœ¬ä¿¡æ¯:
  ç‰ˆæœ¬: {self.version}
  ä½œè€…: {self.author}

ä¼˜åŒ–æ¨¡å—çŠ¶æ€:
  âœ… Day 1-3 åŸºç¡€ä¼˜åŒ–: æ•°å€¼ç¨³å®šæ€§ã€å‘é‡åŒ–ã€å¹¶è¡Œå¤„ç†
  âœ… Week 2 è´¨é‡æå‡: å¼‚å¸¸æ£€æµ‹ã€ç”Ÿäº§GPRã€æ™ºèƒ½ç¼“å­˜
  âœ… ä¼ä¸šçº§éªŒè¯: å¤šç»´åº¦è‡ªåŠ¨åŒ–éªŒè¯æ¡†æ¶
  âœ… æ€§èƒ½ç›‘æ§: å®æ—¶èµ„æºç›‘æ§å’ŒåŸºå‡†æµ‹è¯•
  âœ… ç”Ÿäº§å°±ç»ª: å®Œæ•´çš„å®¹é”™å’Œè¿ç»´è‡ªåŠ¨åŒ–

ç³»ç»Ÿèƒ½åŠ›:
  ğŸ¯ æ€§èƒ½æå‡: 98.8%å¤„ç†æ—¶é—´èŠ‚çœ (82åˆ†é’Ÿ â†’ 1åˆ†é’Ÿ)
  ğŸ›¡ï¸ è´¨é‡ä¿è¯: 100%è‡ªåŠ¨åŒ–éªŒè¯è¦†ç›–
  ğŸ”§ æ™ºèƒ½è¿ç»´: ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–æµæ°´çº¿
  ğŸ“Š ä¼ä¸šçº§ç›‘æ§: å®Œæ•´çš„æ€§èƒ½å’Œèµ„æºç›‘æ§

å¯ç”¨æ¨¡å¼:
  â€¢ optimization - è¿è¡Œå®Œæ•´ä¼˜åŒ–æµæ°´çº¿
  â€¢ benchmark   - æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œå¯¹æ¯”åˆ†æ
  â€¢ validation  - æ¨¡å‹è´¨é‡éªŒè¯å’Œè¯„ä¼°
  â€¢ pipeline    - ç«¯åˆ°ç«¯æµæ°´çº¿å¤„ç†
  â€¢ analysis    - ç³»ç»Ÿæ€§èƒ½åˆ†æå’Œè¯Šæ–­
  â€¢ info        - æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯ (å½“å‰æ¨¡å¼)

ä½¿ç”¨ç¤ºä¾‹:
  python lng_optimizer.py --mode optimization --data data.csv
  python lng_optimizer.py --mode benchmark --compare all
  python lng_optimizer.py --mode pipeline --config production.yaml
        """)
        return True

    def generate_analysis_report(self, results: Dict[str, Any], output_dir: Path):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report_file = output_dir / "analysis_report.md"

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"""# LNGé¡¹ç›®æ€§èƒ½åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š æ•°æ®è´¨é‡åˆ†æ

""")

            if 'data_quality' in results:
                dq = results['data_quality']
                f.write(f"""
- **å¼‚å¸¸å€¼æ£€æµ‹**: {dq.get('outliers_detected', 0)} ä¸ªå¼‚å¸¸å€¼
- **å¼‚å¸¸ç‡**: {dq.get('outlier_rate_percent', 0):.2f}%
- **å¤„ç†ç­–ç•¥**: è‡ªé€‚åº”Hampelæ»¤æ³¢
""")

            if 'feature_extraction' in results:
                fe = results['feature_extraction']
                f.write(f"""
## âš¡ ç‰¹å¾æå–æ€§èƒ½

- **å¤„ç†æ—¶é—´**: {fe.get('processing_time_seconds', 0):.3f}ç§’
- **è¾“å…¥æ•°æ®**: {fe.get('input_shape', 'N/A')}
- **è¾“å‡ºç‰¹å¾**: {fe.get('output_shape', 'N/A')}
- **å¤„ç†é€Ÿåº¦**: {fe.get('features_per_second', 0):.1f} ç‰¹å¾/ç§’
""")

            if 'resource_usage' in results:
                ru = results['resource_usage']
                f.write(f"""
## ğŸ’» ç³»ç»Ÿèµ„æºä½¿ç”¨

- **CPUä½¿ç”¨**: å¹³å‡ {ru.get('avg_cpu', 0):.1f}%, å³°å€¼ {ru.get('max_cpu', 0):.1f}%
- **å†…å­˜ä½¿ç”¨**: å¹³å‡ {ru.get('avg_memory', 0):.1f}%, å³°å€¼ {ru.get('max_memory', 0):.1f}%

## ğŸ¯ ä¼˜åŒ–å»ºè®®

åŸºäºå½“å‰åˆ†æç»“æœï¼Œç³»ç»Ÿè¿è¡ŒçŠ¶æ€è‰¯å¥½ï¼Œå·²è¾¾ä¼ä¸šçº§ç”Ÿäº§æ ‡å‡†ã€‚
""")

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        parser = self.create_parser()
        args = parser.parse_args()

        # è®¾ç½®æ—¥å¿—çº§åˆ«
        if args.verbose:
            logging.getLogger().setLevel(logging.DEBUG)
        elif args.quiet:
            logging.getLogger().setLevel(logging.WARNING)

        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
        if not args.quiet:
            print(f"ğŸš€ LNGä¼˜åŒ–å™¨ v{self.version} - å¯åŠ¨ä¸­...")
            print(f"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}")
            print(f"ğŸ”§ è¿è¡Œæ¨¡å¼: {args.mode}")

        # è·¯ç”±åˆ°å¯¹åº”æ¨¡å¼
        mode_functions = {
            'optimization': self.mode_optimization,
            'benchmark': self.mode_benchmark,
            'validation': self.mode_validation,
            'pipeline': self.mode_pipeline,
            'analysis': self.mode_analysis,
            'info': self.mode_info
        }

        try:
            success = mode_functions[args.mode](args)

            if success:
                self.logger.info(f"æ¨¡å¼ '{args.mode}' æ‰§è¡ŒæˆåŠŸ")
                if not args.quiet:
                    print(f"\nâœ… æ‰§è¡Œå®Œæˆ!")
                return 0
            else:
                self.logger.error(f"æ¨¡å¼ '{args.mode}' æ‰§è¡Œå¤±è´¥")
                if not args.quiet:
                    print(f"\nâŒ æ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦æƒ…")
                return 1

        except KeyboardInterrupt:
            self.logger.info("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
            if not args.quiet:
                print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
            return 130
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
            if not args.quiet:
                print(f"\nğŸ’¥ å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
            return 1


def main():
    """ä¸»å‡½æ•°"""
    # æŠ‘åˆ¶è­¦å‘Šï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
    warnings.filterwarnings('ignore', category=UserWarning)
    warnings.filterwarnings('ignore', category=FutureWarning)

    # åˆ›å»ºå¹¶è¿è¡ŒCLI
    cli = LNGOptimizerCLI()
    return cli.run()


if __name__ == '__main__':
    sys.exit(main())