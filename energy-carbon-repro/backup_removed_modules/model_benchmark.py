#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹æ€§èƒ½å¯¹æ¯”åŸºå‡†
Model Performance Comparison Benchmark

ä¸ºæ¨¡å‹å¯¹æ¯”ç ”ç©¶æä¾›å¿«é€Ÿå®éªŒå¹³å°
"""

import sys
import pandas as pd
import numpy as np
import torch
import logging
import time
from pathlib import Path
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ModelBenchmark:
    """æ¨¡å‹æ€§èƒ½å¯¹æ¯”åŸºå‡†"""

    def __init__(self, data_size=50000):
        """
        åˆå§‹åŒ–åŸºå‡†æµ‹è¯•

        Args:
            data_size: ç”¨äºå¯¹æ¯”çš„æ•°æ®é‡
        """
        self.data_size = data_size
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    def load_benchmark_data(self):
        """åŠ è½½åŸºå‡†æ•°æ®"""
        logger.info(f"åŠ è½½åŸºå‡†æ•°æ® ({self.data_size} è¡Œ)...")

        df = pd.read_csv('data/sim_lng/enhanced_simulation_data.csv',
                         parse_dates=['ts'], nrows=self.data_size)

        power_columns = ['booster_pump_power_kw', 'hp_pump_power_kw', 'bog_compressor_total_power_kw']
        df['energy'] = df[power_columns].sum(axis=1)

        logger.info(f"æ•°æ®ç‰¹æ€§: å‡å€¼={df['energy'].mean():.2f}, CV={df['energy'].std()/df['energy'].mean():.4f}")
        return df

    def extract_baseline_features(self, df):
        """æå–åŸºå‡†ç‰¹å¾ (å¿«é€Ÿç‰ˆæœ¬)"""
        logger.info("æå–åŸºå‡†ç‰¹å¾...")

        # ç®€åŒ–çš„çª—å£ç‰¹å¾
        window_size, stride = 180, 30
        features_list = []
        labels_list = []

        for i in range(0, len(df) - window_size + 1, stride):
            window = df.iloc[i:i+window_size]

            # å¿«é€Ÿç»Ÿè®¡ç‰¹å¾
            feature_data = window.drop(columns=['ts', 'energy']).values
            features = np.concatenate([
                np.mean(feature_data, axis=0),    # å‡å€¼
                np.std(feature_data, axis=0),     # æ ‡å‡†å·®
                np.min(feature_data, axis=0),     # æœ€å°å€¼
                np.max(feature_data, axis=0),     # æœ€å¤§å€¼
            ])

            features_list.append(features)
            labels_list.append(window['energy'].mean())

        X = np.array(features_list)
        y = np.array(labels_list)

        logger.info(f"åŸºå‡†ç‰¹å¾: {X.shape}, æ ‡ç­¾: {y.shape}")
        return X, y

    def benchmark_models(self, X, y):
        """å¯¹æ¯”å¤šä¸ªæ¨¡å‹æ€§èƒ½"""
        logger.info("\n" + "=" * 60)
        logger.info("æ¨¡å‹æ€§èƒ½å¯¹æ¯”åŸºå‡†æµ‹è¯•")
        logger.info("=" * 60)

        # è®­ç»ƒéªŒè¯åˆ†å‰²
        split_idx = len(X) // 2
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]

        # æ ‡å‡†åŒ–
        scaler_X = StandardScaler().fit(X_train)
        scaler_y = StandardScaler().fit(y_train.reshape(-1, 1))

        X_train_s = scaler_X.transform(X_train)
        X_val_s = scaler_X.transform(X_val)
        y_train_s = scaler_y.transform(y_train.reshape(-1, 1)).flatten()
        y_val_s = scaler_y.transform(y_val.reshape(-1, 1)).flatten()

        results = {}

        # 1. çº¿æ€§å›å½’åŸºå‡†
        logger.info("\n1. çº¿æ€§å›å½’åŸºå‡†")
        lr = LinearRegression()
        start_time = time.time()
        lr.fit(X_train_s, y_train_s)
        lr_pred = lr.predict(X_val_s)
        lr_time = time.time() - start_time

        lr_pred_orig = scaler_y.inverse_transform(lr_pred.reshape(-1, 1)).flatten()
        y_val_orig = scaler_y.inverse_transform(y_val_s.reshape(-1, 1)).flatten()

        results['LinearRegression'] = {
            'r2': r2_score(y_val_orig, lr_pred_orig),
            'cv_rmse': np.sqrt(mean_squared_error(y_val_orig, lr_pred_orig)) / np.mean(y_val_orig),
            'training_time': lr_time
        }

        # 2. éšæœºæ£®æ—
        logger.info("\n2. éšæœºæ£®æ—")
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        start_time = time.time()
        rf.fit(X_train_s, y_train_s)
        rf_pred = rf.predict(X_val_s)
        rf_time = time.time() - start_time

        rf_pred_orig = scaler_y.inverse_transform(rf_pred.reshape(-1, 1)).flatten()

        results['RandomForest'] = {
            'r2': r2_score(y_val_orig, rf_pred_orig),
            'cv_rmse': np.sqrt(mean_squared_error(y_val_orig, rf_pred_orig)) / np.mean(y_val_orig),
            'training_time': rf_time
        }

        # 3. è·¨æ¨¡æ€èåˆ (å¦‚æœå¯ç”¨)
        logger.info("\n3. è·¨æ¨¡æ€èåˆ (ç®€åŒ–)")
        try:
            from src.models.cross_modal_fusion import CrossModalFusionWithResidual

            # ä¸ºè·¨æ¨¡æ€å‡†å¤‡æ•°æ® (ç®€åŒ–ç‰ˆæœ¬)
            X_dynamic = X_train_s.reshape(len(X_train_s), -1, 1)  # ç®€åŒ–ä¸ºå•ç‰¹å¾æ—¶åº
            X_static = np.random.randn(len(X_train_s), 32)  # éšæœºé™æ€ç‰¹å¾

            model = CrossModalFusionWithResidual(
                dynamic_dim=1,
                static_dim=32,
                seq_len=X_dynamic.shape[1],
                d_model=64,  # å‡å°æ¨¡å‹ä»¥å¿«é€Ÿè®­ç»ƒ
                n_heads=2,
                n_layers=2
            ).to(self.device)

            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
            criterion = torch.nn.MSELoss()

            # è½¬æ¢æ•°æ®
            train_dynamic = torch.FloatTensor(X_dynamic).to(self.device)
            train_static = torch.FloatTensor(X_static).to(self.device)
            train_labels = torch.FloatTensor(y_train_s).unsqueeze(1).to(self.device)

            start_time = time.time()
            model.train()
            for epoch in range(10):  # å¿«é€Ÿè®­ç»ƒ
                optimizer.zero_grad()
                pred, _ = model(train_dynamic, train_static)
                loss = criterion(pred, train_labels)
                if torch.isfinite(loss):
                    loss.backward()
                    optimizer.step()

            cross_modal_time = time.time() - start_time

            # ç®€åŒ–è¯„ä¼°
            model.eval()
            X_val_dynamic = X_val_s.reshape(len(X_val_s), -1, 1)
            X_val_static = np.random.randn(len(X_val_s), 32)

            with torch.no_grad():
                val_dynamic = torch.FloatTensor(X_val_dynamic).to(self.device)
                val_static = torch.FloatTensor(X_val_static).to(self.device)
                cm_pred, _ = model(val_dynamic, val_static)
                cm_pred_cpu = cm_pred.cpu().numpy().flatten()

            cm_pred_orig = scaler_y.inverse_transform(cm_pred_cpu.reshape(-1, 1)).flatten()

            results['CrossModalFusion'] = {
                'r2': r2_score(y_val_orig, cm_pred_orig),
                'cv_rmse': np.sqrt(mean_squared_error(y_val_orig, cm_pred_orig)) / np.mean(y_val_orig),
                'training_time': cross_modal_time
            }

        except Exception as e:
            logger.warning(f"è·¨æ¨¡æ€èåˆæµ‹è¯•å¤±è´¥: {e}")
            results['CrossModalFusion'] = {'error': str(e)}

        return results

    def print_comparison_results(self, results):
        """æ‰“å°å¯¹æ¯”ç»“æœ"""
        logger.info("\n" + "=" * 60)
        logger.info("æ¨¡å‹æ€§èƒ½å¯¹æ¯”ç»“æœ")
        logger.info("=" * 60)

        for model_name, metrics in results.items():
            if 'error' in metrics:
                logger.info(f"\n{model_name}: æµ‹è¯•å¤±è´¥ ({metrics['error']})")
                continue

            logger.info(f"\n{model_name}:")
            logger.info(f"  RÂ² Score: {metrics['r2']:.4f}")
            logger.info(f"  CV(RMSE): {metrics['cv_rmse']:.4f}")
            logger.info(f"  è®­ç»ƒæ—¶é—´: {metrics['training_time']:.2f}ç§’")

            # è¯„ä¼°æ˜¯å¦è¾¾æ ‡
            r2_pass = "âœ…" if metrics['r2'] >= 0.75 else "âŒ"
            cv_pass = "âœ…" if metrics['cv_rmse'] <= 0.06 else "âŒ"

            logger.info(f"  è®ºæ–‡æŒ‡æ ‡: RÂ² {r2_pass}, CV(RMSE) {cv_pass}")

def run_model_benchmark():
    """è¿è¡Œæ¨¡å‹å¯¹æ¯”åŸºå‡†"""
    benchmark = ModelBenchmark(data_size=20000)  # å¿«é€Ÿå¯¹æ¯”ç”¨è¾ƒå°æ•°æ®é›†

    # åŠ è½½æ•°æ®
    df = benchmark.load_benchmark_data()

    # æå–ç‰¹å¾
    X, y = benchmark.extract_baseline_features(df)

    # è¿è¡Œå¯¹æ¯”
    results = benchmark.benchmark_models(X, y)

    # æ˜¾ç¤ºç»“æœ
    benchmark.print_comparison_results(results)

    logger.info("\nğŸ¯ å¯¹æ¯”åŸºå‡†å»ºç«‹å®Œæˆï¼Œå¯ç”¨äºæ¨¡å‹ç ”ç©¶")

if __name__ == "__main__":
    run_model_benchmark()