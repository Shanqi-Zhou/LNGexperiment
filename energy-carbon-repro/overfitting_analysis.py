#!/usr/bin/env python3
"""
LNGå®éªŒè¿‡æ‹Ÿåˆåˆ†æè„šæœ¬
æ·±å…¥åˆ†ææ¨¡å‹æ˜¯å¦å­˜åœ¨è¿‡æ‹Ÿåˆé—®é¢˜
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score, validation_curve, learning_curve
from sklearn.metrics import r2_score, mean_squared_error
import logging
import json
from pathlib import Path
import warnings
import sys

warnings.filterwarnings('ignore')
sys.path.insert(0, 'src')

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def load_data():
    """åŠ è½½æ•°æ®"""
    logger = setup_logging()
    
    data = pd.read_csv('data/sim_lng/full_simulation_data.csv', low_memory=False)
    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()
    data_clean = data[numeric_columns].copy()
    data_clean = data_clean.fillna(data_clean.median())
    
    X = data_clean.drop(columns=['orv_Q_MW'])
    y = data_clean['orv_Q_MW']
    
    return X, y

def analyze_data_characteristics(X, y):
    """åˆ†ææ•°æ®ç‰¹å¾ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿‡æ‹Ÿåˆçš„æ ¹æº"""
    logger = setup_logging()
    
    logger.info("=" * 80)
    logger.info("æ•°æ®ç‰¹å¾åˆ†æ - è¿‡æ‹Ÿåˆé£é™©è¯„ä¼°")
    logger.info("=" * 80)
    
    # 1. æ•°æ®è§„æ¨¡åˆ†æ
    n_samples, n_features = X.shape
    logger.info(f"æ•°æ®è§„æ¨¡: {n_samples} æ ·æœ¬, {n_features} ç‰¹å¾")
    logger.info(f"æ ·æœ¬/ç‰¹å¾æ¯”: {n_samples/n_features:.1f}:1")
    
    # 2. ç›®æ ‡å˜é‡åˆ†æ
    logger.info(f"\nç›®æ ‡å˜é‡ç»Ÿè®¡:")
    logger.info(f"  å‡å€¼: {y.mean():.6f}")
    logger.info(f"  æ ‡å‡†å·®: {y.std():.6f}")
    logger.info(f"  å˜å¼‚ç³»æ•°: {(y.std()/y.mean()*100):.2f}%")
    logger.info(f"  èŒƒå›´: [{y.min():.6f}, {y.max():.6f}]")
    
    # 3. æ£€æŸ¥æ•°æ®é‡å¤
    duplicate_rows = X.duplicated().sum()
    logger.info(f"\né‡å¤è¡Œæ•°é‡: {duplicate_rows} ({duplicate_rows/len(X)*100:.2f}%)")
    
    # 4. ç‰¹å¾ç›¸å…³æ€§åˆ†æ
    corr_with_target = X.corrwith(y).abs().sort_values(ascending=False)
    high_corr_features = corr_with_target[corr_with_target > 0.9]
    logger.info(f"\né«˜ç›¸å…³æ€§ç‰¹å¾ (|r| > 0.9): {len(high_corr_features)} ä¸ª")
    
    if len(high_corr_features) > 0:
        logger.info("å‰5ä¸ªæœ€é«˜ç›¸å…³æ€§ç‰¹å¾:")
        for i, (feature, corr) in enumerate(high_corr_features.head().items()):
            logger.info(f"  {i+1}. {feature}: {corr:.4f}")
    
    # 5. æ£€æŸ¥æ•°æ®æ³„éœ²é£é™©
    # å¯»æ‰¾ä¸ç›®æ ‡å˜é‡å‡ ä¹å®Œå…¨ç›¸å…³çš„ç‰¹å¾
    perfect_corr_features = corr_with_target[corr_with_target > 0.99]
    if len(perfect_corr_features) > 0:
        logger.info(f"\nâš ï¸ è­¦å‘Š: å‘ç° {len(perfect_corr_features)} ä¸ªå‡ ä¹å®Œç¾ç›¸å…³çš„ç‰¹å¾ (|r| > 0.99):")
        for feature, corr in perfect_corr_features.items():
            logger.info(f"  - {feature}: {corr:.6f}")
        logger.info("  è¿™å¯èƒ½è¡¨æ˜å­˜åœ¨æ•°æ®æ³„éœ²æˆ–ç›®æ ‡å˜é‡çš„ç›´æ¥è®¡ç®—å…³ç³»!")
    
    # 6. ç‰¹å¾é—´å…±çº¿æ€§åˆ†æ
    feature_corr = X.corr().abs()
    high_inter_corr = []
    for i in range(len(feature_corr.columns)):
        for j in range(i+1, len(feature_corr.columns)):
            if feature_corr.iloc[i,j] > 0.95:
                high_inter_corr.append((feature_corr.columns[i], feature_corr.columns[j], feature_corr.iloc[i,j]))
    
    logger.info(f"\né«˜å…±çº¿æ€§ç‰¹å¾å¯¹ (|r| > 0.95): {len(high_inter_corr)} å¯¹")
    if len(high_inter_corr) > 5:
        logger.info("å‰5å¯¹:")
        for feat1, feat2, corr in high_inter_corr[:5]:
            logger.info(f"  {feat1} - {feat2}: {corr:.4f}")
    
    return {
        'n_samples': n_samples,
        'n_features': n_features,
        'duplicate_rows': duplicate_rows,
        'high_corr_features': len(high_corr_features),
        'perfect_corr_features': len(perfect_corr_features),
        'high_inter_corr': len(high_inter_corr),
        'target_variance': y.var(),
        'perfect_corr_list': list(perfect_corr_features.index) if len(perfect_corr_features) > 0 else []
    }

def cross_validation_analysis(X, y):
    """äº¤å‰éªŒè¯åˆ†ææ£€æµ‹è¿‡æ‹Ÿåˆ"""
    logger = setup_logging()
    
    logger.info("\n" + "=" * 80)
    logger.info("äº¤å‰éªŒè¯åˆ†æ - è¿‡æ‹Ÿåˆæ£€æµ‹")
    logger.info("=" * 80)
    
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import Ridge
    from sklearn.model_selection import KFold, TimeSeriesSplit
    
    # ä½¿ç”¨å¤šç§äº¤å‰éªŒè¯ç­–ç•¥
    cv_strategies = {
        'KFold_5': KFold(n_splits=5, shuffle=True, random_state=42),
        'KFold_10': KFold(n_splits=10, shuffle=True, random_state=42),
        'TimeSeries': TimeSeriesSplit(n_splits=5)  # è€ƒè™‘æ—¶é—´åºåˆ—ç‰¹æ€§
    }
    
    models = {
        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
        'Ridge': Ridge(alpha=1.0)
    }
    
    results = {}
    
    for model_name, model in models.items():
        logger.info(f"\n{model_name} äº¤å‰éªŒè¯ç»“æœ:")
        model_results = {}
        
        for cv_name, cv_strategy in cv_strategies.items():
            try:
                scores = cross_val_score(model, X, y, cv=cv_strategy, scoring='r2')
                
                logger.info(f"  {cv_name}:")
                logger.info(f"    å¹³å‡ RÂ²: {scores.mean():.6f}")
                logger.info(f"    æ ‡å‡†å·®: {scores.std():.6f}")
                logger.info(f"    èŒƒå›´: [{scores.min():.6f}, {scores.max():.6f}]")
                logger.info(f"    å˜å¼‚ç³»æ•°: {(scores.std()/abs(scores.mean())*100):.3f}%")
                
                model_results[cv_name] = {
                    'mean': scores.mean(),
                    'std': scores.std(),
                    'min': scores.min(),
                    'max': scores.max(),
                    'scores': scores.tolist()
                }
                
            except Exception as e:
                logger.warning(f"    {cv_name} å¤±è´¥: {e}")
                model_results[cv_name] = None
        
        results[model_name] = model_results
    
    # åˆ†æäº¤å‰éªŒè¯ç»“æœ
    logger.info("\nè¿‡æ‹Ÿåˆé£é™©è¯„ä¼°:")
    
    for model_name, model_results in results.items():
        logger.info(f"\n{model_name}:")
        for cv_name, cv_result in model_results.items():
            if cv_result is not None:
                cv_coef = cv_result['std'] / abs(cv_result['mean']) * 100
                if cv_coef < 1:
                    risk_level = "ä½ âœ“"
                elif cv_coef < 5:
                    risk_level = "ä¸­ç­‰ âš ï¸"
                else:
                    risk_level = "é«˜ âŒ"
                
                logger.info(f"  {cv_name}: å˜å¼‚ç³»æ•° {cv_coef:.3f}% - è¿‡æ‹Ÿåˆé£é™©: {risk_level}")
    
    return results

def learning_curve_analysis(X, y):
    """å­¦ä¹ æ›²çº¿åˆ†æ"""
    logger = setup_logging()
    
    logger.info("\n" + "=" * 80)
    logger.info("å­¦ä¹ æ›²çº¿åˆ†æ")
    logger.info("=" * 80)
    
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import learning_curve
    
    # é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬è¿›è¡Œå­¦ä¹ æ›²çº¿åˆ†æï¼ˆå¤§æ•°æ®é›†å¤ªæ…¢ï¼‰
    if len(X) > 50000:
        indices = np.random.choice(len(X), 50000, replace=False)
        X_sample = X.iloc[indices]
        y_sample = y.iloc[indices]
        logger.info("ä½¿ç”¨5ä¸‡æ ·æœ¬å­é›†è¿›è¡Œå­¦ä¹ æ›²çº¿åˆ†æ")
    else:
        X_sample = X
        y_sample = y
    
    model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
    
    train_sizes = np.linspace(0.1, 1.0, 10)
    
    try:
        train_sizes_abs, train_scores, val_scores = learning_curve(
            model, X_sample, y_sample, 
            train_sizes=train_sizes,
            cv=5,
            scoring='r2',
            n_jobs=-1,
            random_state=42
        )
        
        train_mean = train_scores.mean(axis=1)
        train_std = train_scores.std(axis=1)
        val_mean = val_scores.mean(axis=1)
        val_std = val_scores.std(axis=1)
        
        logger.info("å­¦ä¹ æ›²çº¿ç»“æœ:")
        logger.info("æ ·æœ¬é‡ | è®­ç»ƒRÂ² | éªŒè¯RÂ² | å·®å¼‚ | è¿‡æ‹Ÿåˆåˆ¤æ–­")
        logger.info("-" * 60)
        
        for i, size in enumerate(train_sizes_abs):
            diff = train_mean[i] - val_mean[i]
            if diff > 0.1:
                overfitting = "ä¸¥é‡è¿‡æ‹Ÿåˆ âŒ"
            elif diff > 0.05:
                overfitting = "è½»å¾®è¿‡æ‹Ÿåˆ âš ï¸"
            elif diff > 0.01:
                overfitting = "å¯èƒ½è¿‡æ‹Ÿåˆ ?"
            else:
                overfitting = "æ­£å¸¸ âœ“"
                
            logger.info(f"{size:6d} | {train_mean[i]:.4f} | {val_mean[i]:.4f} | {diff:+.4f} | {overfitting}")
        
        # ä¿å­˜å­¦ä¹ æ›²çº¿æ•°æ®
        learning_curve_data = {
            'train_sizes': train_sizes_abs.tolist(),
            'train_scores_mean': train_mean.tolist(),
            'train_scores_std': train_std.tolist(),
            'val_scores_mean': val_mean.tolist(),
            'val_scores_std': val_std.tolist()
        }
        
        return learning_curve_data
        
    except Exception as e:
        logger.error(f"å­¦ä¹ æ›²çº¿åˆ†æå¤±è´¥: {e}")
        return None

def residual_analysis(X, y):
    """æ®‹å·®åˆ†æ"""
    logger = setup_logging()
    
    logger.info("\n" + "=" * 80)
    logger.info("æ®‹å·®åˆ†æ")
    logger.info("=" * 80)
    
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestRegressor
    
    # æ•°æ®åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # è®­ç»ƒæ¨¡å‹
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # è®¡ç®—æ®‹å·®
    residuals_train = y_train - y_pred_train
    residuals_test = y_test - y_pred_test
    
    logger.info("æ®‹å·®ç»Ÿè®¡:")
    logger.info(f"è®­ç»ƒé›†æ®‹å·®:")
    logger.info(f"  å‡å€¼: {residuals_train.mean():.8f}")
    logger.info(f"  æ ‡å‡†å·®: {residuals_train.std():.8f}")
    logger.info(f"  èŒƒå›´: [{residuals_train.min():.8f}, {residuals_train.max():.8f}]")
    
    logger.info(f"æµ‹è¯•é›†æ®‹å·®:")
    logger.info(f"  å‡å€¼: {residuals_test.mean():.8f}")
    logger.info(f"  æ ‡å‡†å·®: {residuals_test.std():.8f}")
    logger.info(f"  èŒƒå›´: [{residuals_test.min():.8f}, {residuals_test.max():.8f}]")
    
    # æ®‹å·®åˆ†æ
    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    
    logger.info(f"\nRMSEæ¯”è¾ƒ:")
    logger.info(f"  è®­ç»ƒé›† RMSE: {train_rmse:.8f}")
    logger.info(f"  æµ‹è¯•é›† RMSE: {test_rmse:.8f}")
    logger.info(f"  RMSEæ¯”å€¼ (æµ‹è¯•/è®­ç»ƒ): {test_rmse/train_rmse:.4f}")
    
    if test_rmse/train_rmse > 2.0:
        logger.info("  âŒ ä¸¥é‡è¿‡æ‹Ÿåˆ: æµ‹è¯•é›†è¯¯å·®æ˜¯è®­ç»ƒé›†çš„2å€ä»¥ä¸Š")
    elif test_rmse/train_rmse > 1.5:
        logger.info("  âš ï¸ å¯èƒ½è¿‡æ‹Ÿåˆ: æµ‹è¯•é›†è¯¯å·®æ˜æ˜¾é«˜äºè®­ç»ƒé›†")
    elif test_rmse/train_rmse > 1.1:
        logger.info("  ? è½»å¾®è¿‡æ‹Ÿåˆ: æµ‹è¯•é›†è¯¯å·®ç•¥é«˜äºè®­ç»ƒé›†")
    else:
        logger.info("  âœ“ æ³›åŒ–æ€§èƒ½è‰¯å¥½: æµ‹è¯•é›†å’Œè®­ç»ƒé›†è¯¯å·®ç›¸å½“")
    
    return {
        'train_rmse': train_rmse,
        'test_rmse': test_rmse,
        'rmse_ratio': test_rmse/train_rmse,
        'residuals_train_stats': {
            'mean': residuals_train.mean(),
            'std': residuals_train.std(),
            'min': residuals_train.min(),
            'max': residuals_train.max()
        },
        'residuals_test_stats': {
            'mean': residuals_test.mean(),
            'std': residuals_test.std(),
            'min': residuals_test.min(),
            'max': residuals_test.max()
        }
    }

def comprehensive_overfitting_analysis():
    """ç»¼åˆè¿‡æ‹Ÿåˆåˆ†æ"""
    logger = setup_logging()
    
    logger.info("ğŸ” å¼€å§‹LNGå®éªŒè¿‡æ‹Ÿåˆç»¼åˆåˆ†æ")
    logger.info("åˆ†æå¼‚å¸¸é«˜ç²¾åº¦æŒ‡æ ‡çš„åŸå› ")
    
    # åŠ è½½æ•°æ®
    X, y = load_data()
    
    # 1. æ•°æ®ç‰¹å¾åˆ†æ
    data_analysis = analyze_data_characteristics(X, y)
    
    # 2. äº¤å‰éªŒè¯åˆ†æ
    cv_analysis = cross_validation_analysis(X, y)
    
    # 3. å­¦ä¹ æ›²çº¿åˆ†æ
    learning_curve_data = learning_curve_analysis(X, y)
    
    # 4. æ®‹å·®åˆ†æ
    residual_data = residual_analysis(X, y)
    
    # ç»¼åˆç»“è®º
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‹ ç»¼åˆè¿‡æ‹Ÿåˆåˆ†æç»“è®º")
    logger.info("=" * 80)
    
    # è¿‡æ‹Ÿåˆé£é™©è¯„ä¼°
    risk_factors = []
    
    if data_analysis['perfect_corr_features'] > 0:
        risk_factors.append(f"å­˜åœ¨{data_analysis['perfect_corr_features']}ä¸ªå‡ ä¹å®Œç¾ç›¸å…³çš„ç‰¹å¾ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®æ³„éœ²")
    
    if data_analysis['duplicate_rows'] > len(X) * 0.01:
        risk_factors.append(f"é‡å¤æ•°æ®å æ¯”{data_analysis['duplicate_rows']/len(X)*100:.1f}%ï¼Œå¯èƒ½å½±å“æ³›åŒ–èƒ½åŠ›")
    
    if residual_data['rmse_ratio'] > 1.5:
        risk_factors.append(f"æµ‹è¯•é›†RMSEæ˜¯è®­ç»ƒé›†çš„{residual_data['rmse_ratio']:.2f}å€ï¼Œå­˜åœ¨è¿‡æ‹Ÿåˆ")
    
    if len(risk_factors) == 0:
        logger.info("âœ… è¿‡æ‹Ÿåˆé£é™©è¯„ä¼°: ä½é£é™©")
        logger.info("   æ¨¡å‹è¡¨ç°ä¼˜å¼‚ï¼Œæ³›åŒ–èƒ½åŠ›è‰¯å¥½")
    else:
        logger.info("âš ï¸ å‘ç°è¿‡æ‹Ÿåˆé£é™©å› ç´ :")
        for i, factor in enumerate(risk_factors, 1):
            logger.info(f"   {i}. {factor}")
    
    # ä¿å­˜åˆ†æç»“æœ
    analysis_results = {
        'data_characteristics': data_analysis,
        'cross_validation': cv_analysis,
        'learning_curve': learning_curve_data,
        'residual_analysis': residual_data,
        'risk_factors': risk_factors,
        'overall_risk': 'low' if len(risk_factors) == 0 else 'medium' if len(risk_factors) < 3 else 'high'
    }
    
    output_dir = Path('results')
    with open(output_dir / 'overfitting_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nğŸ“ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}/overfitting_analysis.json")
    
    return analysis_results

if __name__ == '__main__':
    results = comprehensive_overfitting_analysis()